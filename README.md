# gcp-dataflow-tweets

## Project Documentation: Data Pipeline with Apache Beam
This project involves creating a data pipeline using Apache Beam to generate fake social network tweets. The pipeline uses Google Cloud Pub/Sub to ingest data and stores the processed data in a BigQuery table. Additionally, the pipeline includes a flagging mechanism to identify dangerous words in the tweets.

## Prerequisites
1. Python 3.x installed on your machine.
2. Google Cloud Platform (GCP) account with necessary permissions to access Pub/Sub and BigQuery services.
3. Virtual Python environment set up (optional but recommended).

### Step 1: Installation
1. Clone the project repository from GitHub:

```sh
git clone <repository_url>

```
3. Navigate to the project directory
